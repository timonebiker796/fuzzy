"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.useLLMsModels = void 0;
var _i18n = require("@kbn/i18n");
var _common = require("@kbn/stack-connectors-plugin/public/common");
var _react = require("react");
var _types = require("../../common/types");
var _use_load_connectors = require("./use_load_connectors");
var _models = require("../../common/models");
/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */

const mapLlmToModels = {
  [_types.LLMs.openai]: {
    icon: _common.OpenAILogo,
    getModels: (connectorName, includeName) => _models.MODELS.filter(({
      provider
    }) => provider === _types.LLMs.openai).map(model => ({
      label: `${model.name} ${includeName ? `(${connectorName})` : ''}`,
      value: model.model,
      promptTokenLimit: model.promptTokenLimit
    }))
  },
  [_types.LLMs.openai_azure]: {
    icon: _common.OpenAILogo,
    getModels: (connectorName, includeName) => [{
      label: _i18n.i18n.translate('xpack.searchPlayground.openAIAzureModel', {
        defaultMessage: 'Azure OpenAI {name}',
        values: {
          name: includeName ? `(${connectorName})` : ''
        }
      })
    }]
  },
  [_types.LLMs.bedrock]: {
    icon: _common.BedrockLogo,
    getModels: () => _models.MODELS.filter(({
      provider
    }) => provider === _types.LLMs.bedrock).map(model => ({
      label: model.name,
      value: model.model,
      promptTokenLimit: model.promptTokenLimit
    }))
  },
  [_types.LLMs.gemini]: {
    icon: _common.GeminiLogo,
    getModels: () => _models.MODELS.filter(({
      provider
    }) => provider === _types.LLMs.gemini).map(model => ({
      label: model.name,
      value: model.model,
      promptTokenLimit: model.promptTokenLimit
    }))
  }
};
const useLLMsModels = () => {
  const {
    data: connectors
  } = (0, _use_load_connectors.useLoadConnectors)();
  const mapConnectorTypeToCount = (0, _react.useMemo)(() => connectors === null || connectors === void 0 ? void 0 : connectors.reduce((result, connector) => ({
    ...result,
    [connector.type]: (result[connector.type] || 0) + 1
  }), {}), [connectors]);
  return (0, _react.useMemo)(() => (connectors === null || connectors === void 0 ? void 0 : connectors.reduce((result, connector) => {
    const llmParams = mapLlmToModels[connector.type];
    if (!llmParams) {
      return result;
    }
    const showConnectorName = Number(mapConnectorTypeToCount === null || mapConnectorTypeToCount === void 0 ? void 0 : mapConnectorTypeToCount[connector.type]) > 1;
    return [...result, ...llmParams.getModels(connector.name, false).map(({
      label,
      value,
      promptTokenLimit
    }) => ({
      id: (connector === null || connector === void 0 ? void 0 : connector.id) + label,
      name: label,
      value,
      connectorType: connector.type,
      connectorName: connector.name,
      showConnectorName,
      icon: llmParams.icon,
      disabled: !connector,
      connectorId: connector.id,
      promptTokenLimit
    }))];
  }, [])) || [], [connectors, mapConnectorTypeToCount]);
};
exports.useLLMsModels = useLLMsModels;