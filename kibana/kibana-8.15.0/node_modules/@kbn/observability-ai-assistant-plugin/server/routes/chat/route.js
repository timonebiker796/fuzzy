"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.chatRoutes = void 0;
var _boom = require("@hapi/boom");
var _ioTsUtils = require("@kbn/io-ts-utils");
var _api = require("@opentelemetry/api");
var t = _interopRequireWildcard(require("io-ts"));
var _rxjs = require("rxjs");
var _ = require("../..");
var _create_function_response_message = require("../../../common/utils/create_function_response_message");
var _without_token_count_events = require("../../../common/utils/without_token_count_events");
var _lang_tracer = require("../../service/client/instrumentation/lang_tracer");
var _flush_buffer = require("../../service/util/flush_buffer");
var _observable_into_openai_stream = require("../../service/util/observable_into_openai_stream");
var _observable_into_stream = require("../../service/util/observable_into_stream");
var _with_assistant_span = require("../../service/util/with_assistant_span");
var _recall_and_score = require("../../utils/recall/recall_and_score");
var _create_observability_ai_assistant_server_route = require("../create_observability_ai_assistant_server_route");
var _runtime_types = require("../runtime_types");
function _getRequireWildcardCache(e) { if ("function" != typeof WeakMap) return null; var r = new WeakMap(), t = new WeakMap(); return (_getRequireWildcardCache = function (e) { return e ? t : r; })(e); }
function _interopRequireWildcard(e, r) { if (!r && e && e.__esModule) return e; if (null === e || "object" != typeof e && "function" != typeof e) return { default: e }; var t = _getRequireWildcardCache(r); if (t && t.has(e)) return t.get(e); var n = { __proto__: null }, a = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var u in e) if ("default" !== u && {}.hasOwnProperty.call(e, u)) { var i = a ? Object.getOwnPropertyDescriptor(e, u) : null; i && (i.get || i.set) ? Object.defineProperty(n, u, i) : n[u] = e[u]; } return n.default = e, t && t.set(e, n), n; }
/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */

const chatCompleteBaseRt = t.type({
  body: t.intersection([t.type({
    messages: t.array(_runtime_types.messageRt),
    connectorId: t.string,
    persist: _ioTsUtils.toBooleanRt
  }), t.partial({
    conversationId: t.string,
    title: t.string,
    responseLanguage: t.string,
    disableFunctions: t.union([_ioTsUtils.toBooleanRt, t.type({
      except: t.array(t.string)
    })]),
    instructions: t.array(t.union([t.string, t.intersection([t.type({
      doc_id: t.string,
      text: t.string
    }), t.partial({
      system: t.boolean
    })])]))
  })])
});
const chatCompleteInternalRt = t.intersection([chatCompleteBaseRt, t.type({
  body: t.type({
    screenContexts: t.array(_runtime_types.screenContextRt)
  })
})]);
const chatCompletePublicRt = t.intersection([chatCompleteBaseRt, t.partial({
  body: t.partial({
    actions: t.array(_runtime_types.functionRt)
  }),
  query: t.partial({
    format: t.union([t.literal('default'), t.literal('openai')])
  })
})]);
async function initializeChatRequest({
  context,
  request,
  plugins: {
    cloud,
    actions
  },
  params: {
    body: {
      connectorId
    }
  },
  service
}) {
  await (0, _with_assistant_span.withAssistantSpan)('guard_against_invalid_connector', async () => {
    const actionsClient = await (await actions.start()).getActionsClientWithRequest(request);
    const connector = await actionsClient.get({
      id: connectorId,
      throwIfSystemAction: true
    });
    return connector;
  });
  const [client, cloudStart, simulateFunctionCalling] = await Promise.all([service.getClient({
    request
  }), cloud === null || cloud === void 0 ? void 0 : cloud.start(), (await context.core).uiSettings.client.get(_.aiAssistantSimulatedFunctionCalling)]);
  if (!client) {
    throw (0, _boom.notImplemented)();
  }
  const controller = new AbortController();
  request.events.aborted$.subscribe(() => {
    controller.abort();
  });
  return {
    client,
    isCloudEnabled: Boolean(cloudStart === null || cloudStart === void 0 ? void 0 : cloudStart.isCloudEnabled),
    simulateFunctionCalling,
    signal: controller.signal
  };
}
const chatRoute = (0, _create_observability_ai_assistant_server_route.createObservabilityAIAssistantServerRoute)({
  endpoint: 'POST /internal/observability_ai_assistant/chat',
  options: {
    tags: ['access:ai_assistant']
  },
  params: t.type({
    body: t.intersection([t.type({
      name: t.string,
      messages: t.array(_runtime_types.messageRt),
      connectorId: t.string,
      functions: t.array(_runtime_types.functionRt)
    }), t.partial({
      functionCall: t.string
    })])
  }),
  handler: async resources => {
    const {
      params
    } = resources;
    const {
      body: {
        name,
        messages,
        connectorId,
        functions,
        functionCall
      }
    } = params;
    const {
      client,
      simulateFunctionCalling,
      signal,
      isCloudEnabled
    } = await initializeChatRequest(resources);
    const response$ = client.chat(name, {
      messages,
      connectorId,
      signal,
      ...(functions.length ? {
        functions,
        functionCall
      } : {}),
      simulateFunctionCalling,
      tracer: new _lang_tracer.LangTracer(_api.context.active())
    });
    return (0, _observable_into_stream.observableIntoStream)(response$.pipe((0, _flush_buffer.flushBuffer)(isCloudEnabled)));
  }
});
const chatRecallRoute = (0, _create_observability_ai_assistant_server_route.createObservabilityAIAssistantServerRoute)({
  endpoint: 'POST /internal/observability_ai_assistant/chat/recall',
  options: {
    tags: ['access:ai_assistant']
  },
  params: t.type({
    body: t.type({
      prompt: t.string,
      context: t.string,
      connectorId: t.string
    })
  }),
  handler: async resources => {
    const {
      client,
      simulateFunctionCalling,
      signal,
      isCloudEnabled
    } = await initializeChatRequest(resources);
    const {
      connectorId,
      prompt,
      context
    } = resources.params.body;
    const response$ = (0, _rxjs.from)((0, _recall_and_score.recallAndScore)({
      analytics: (await resources.context.core).coreStart.analytics,
      chat: (name, params) => client.chat(name, {
        ...params,
        connectorId,
        simulateFunctionCalling,
        signal,
        tracer: new _lang_tracer.LangTracer(_api.context.active())
      }).pipe((0, _without_token_count_events.withoutTokenCountEvents)()),
      context,
      logger: resources.logger,
      messages: [],
      userPrompt: prompt,
      recall: client.recall,
      signal
    })).pipe((0, _rxjs.map)(({
      scores,
      suggestions,
      relevantDocuments
    }) => {
      return (0, _create_function_response_message.createFunctionResponseMessage)({
        name: 'context',
        data: {
          suggestions,
          scores
        },
        content: {
          relevantDocuments
        }
      });
    }));
    return (0, _observable_into_stream.observableIntoStream)(response$.pipe((0, _flush_buffer.flushBuffer)(isCloudEnabled)));
  }
});
async function chatComplete(resources) {
  const {
    params,
    service
  } = resources;
  const {
    body: {
      messages,
      connectorId,
      conversationId,
      title,
      persist,
      screenContexts,
      responseLanguage,
      instructions,
      disableFunctions
    }
  } = params;
  const {
    client,
    isCloudEnabled,
    signal,
    simulateFunctionCalling
  } = await initializeChatRequest(resources);
  const functionClient = await service.getFunctionClient({
    signal,
    resources,
    client,
    screenContexts
  });
  const response$ = client.complete({
    messages,
    connectorId,
    conversationId,
    title,
    persist,
    signal,
    functionClient,
    responseLanguage,
    instructions,
    simulateFunctionCalling,
    disableFunctions
  });
  return response$.pipe((0, _flush_buffer.flushBuffer)(isCloudEnabled));
}
const chatCompleteRoute = (0, _create_observability_ai_assistant_server_route.createObservabilityAIAssistantServerRoute)({
  endpoint: 'POST /internal/observability_ai_assistant/chat/complete',
  options: {
    tags: ['access:ai_assistant']
  },
  params: chatCompleteInternalRt,
  handler: async resources => {
    return (0, _observable_into_stream.observableIntoStream)(await chatComplete(resources));
  }
});
const publicChatCompleteRoute = (0, _create_observability_ai_assistant_server_route.createObservabilityAIAssistantServerRoute)({
  endpoint: 'POST /api/observability_ai_assistant/chat/complete 2023-10-31',
  options: {
    tags: ['access:ai_assistant']
  },
  params: chatCompletePublicRt,
  handler: async resources => {
    const {
      params,
      logger
    } = resources;
    const {
      body: {
        actions,
        ...restOfBody
      },
      query = {}
    } = params;
    const {
      format = 'default'
    } = query;
    const response$ = await chatComplete({
      ...resources,
      params: {
        body: {
          ...restOfBody,
          screenContexts: [{
            actions
          }]
        }
      }
    });
    return format === 'openai' ? (0, _observable_into_openai_stream.observableIntoOpenAIStream)(response$, logger) : (0, _observable_into_stream.observableIntoStream)(response$);
  }
});
const chatRoutes = exports.chatRoutes = {
  ...chatRoute,
  ...chatRecallRoute,
  ...chatCompleteRoute,
  ...publicChatCompleteRoute
};