"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.LangtraceServiceProvider = void 0;
exports.withLangtraceChatCompleteSpan = withLangtraceChatCompleteSpan;
var _traceAttributes = require("@langtrase/trace-attributes");
var _rxjs = require("rxjs");
var _common = require("../../../../common");
var _concatenate_chat_completion_chunks = require("../../../../common/utils/concatenate_chat_completion_chunks");
var _without_token_count_events = require("../../../../common/utils/without_token_count_events");
var _get_langtrace_span_attributes = require("../instrumentation/get_langtrace_span_attributes");
/*
 * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
 * or more contributor license agreements. Licensed under the Elastic License
 * 2.0; you may not use this file except in compliance with the Elastic License
 * 2.0.
 */
let LangtraceServiceProvider = exports.LangtraceServiceProvider = /*#__PURE__*/function (LangtraceServiceProvider) {
  LangtraceServiceProvider["OpenAI"] = "OpenAI";
  LangtraceServiceProvider["Azure"] = "Azure";
  LangtraceServiceProvider["Anthropic"] = "Anthropic";
  return LangtraceServiceProvider;
}({});
function withLangtraceChatCompleteSpan({
  span,
  model,
  messages,
  serviceProvider,
  functions
}) {
  const attributes = {
    ...(0, _get_langtrace_span_attributes.getLangtraceSpanAttributes)(),
    'langtrace.service.name': serviceProvider,
    'llm.api': '/chat/completions',
    'http.max.retries': 0,
    // dummy URL
    'url.full': 'http://localhost:3000/chat/completions',
    'http.timeout': 120 * 1000,
    'llm.prompts': JSON.stringify(messages.map(message => ({
      role: message.message.role,
      content: [message.message.content, message.message.function_call ? JSON.stringify(message.message.function_call) : ''].filter(Boolean).join('\n\n')
    }))),
    'llm.model': model,
    'llm.stream': true,
    ...(functions ? {
      'llm.tools': JSON.stringify(functions.map(fn => ({
        function: fn,
        type: 'function'
      })))
    } : {})
  };
  span.setAttributes(attributes);
  return source$ => {
    const shared$ = source$.pipe((0, _rxjs.share)());
    span.addEvent(_traceAttributes.Event.STREAM_START);
    const passThrough$ = shared$.pipe((0, _rxjs.tap)(value => {
      if (value.type === _common.StreamingChatResponseEventType.ChatCompletionChunk) {
        span.addEvent(_traceAttributes.Event.STREAM_OUTPUT, {
          response: value.message.content
        });
        return;
      }
      span.setAttributes({
        'llm.token.counts': JSON.stringify({
          input_tokens: value.tokens.prompt,
          output_tokens: value.tokens.completion,
          total_tokens: value.tokens.total
        })
      });
    }));
    return (0, _rxjs.merge)(passThrough$, shared$.pipe((0, _without_token_count_events.withoutTokenCountEvents)(), (0, _concatenate_chat_completion_chunks.concatenateChatCompletionChunks)(), (0, _rxjs.last)(), (0, _rxjs.tap)(message => {
      span.setAttribute('llm.responses', JSON.stringify([{
        role: 'assistant',
        content: message.message.content
      }]));
    }), (0, _rxjs.ignoreElements)()));
  };
}